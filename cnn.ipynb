{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T19:36:41.130801Z",
     "iopub.status.busy": "2024-07-22T19:36:41.130500Z",
     "iopub.status.idle": "2024-07-22T19:36:44.838728Z",
     "shell.execute_reply": "2024-07-22T19:36:44.837937Z",
     "shell.execute_reply.started": "2024-07-22T19:36:41.130775Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from utilss import get_accuracy, plot_curve, keep_store_dict, store_dict_to_disk\n",
    "from data_loader import ImageDataset\n",
    "from initializers import gaussian_initializer, constant_initializer\n",
    "from models import Model3, ModelM2, ModelM3, Model2, Model1, ModelAVE, Model\n",
    "from test import test\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T19:36:44.841914Z",
     "iopub.status.busy": "2024-07-22T19:36:44.840549Z",
     "iopub.status.idle": "2024-07-22T19:36:45.019406Z",
     "shell.execute_reply": "2024-07-22T19:36:45.018596Z",
     "shell.execute_reply.started": "2024-07-22T19:36:44.841872Z"
    }
   },
   "outputs": [],
   "source": [
    "model1 = Model1()\n",
    "model2 = Model2()\n",
    "modelAVE = ModelAVE()\n",
    "model2_M = ModelM2()\n",
    "model3 = Model3()\n",
    "model3_M = ModelM3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T19:36:45.021091Z",
     "iopub.status.busy": "2024-07-22T19:36:45.020269Z",
     "iopub.status.idle": "2024-07-22T19:36:49.285123Z",
     "shell.execute_reply": "2024-07-22T19:36:49.284408Z",
     "shell.execute_reply.started": "2024-07-22T19:36:45.021065Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(model1, model2, model3, modelAVE, model2_M, model3_M)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T19:36:49.286938Z",
     "iopub.status.busy": "2024-07-22T19:36:49.285973Z",
     "iopub.status.idle": "2024-07-22T19:36:49.290927Z",
     "shell.execute_reply": "2024-07-22T19:36:49.290249Z",
     "shell.execute_reply.started": "2024-07-22T19:36:49.286911Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_test = ImageDataset(\"heat_maps_test_plain\", \"images_test\", (368, 368), model.center_map)\n",
    "dataset_training = ImageDataset(\"heat_maps_training_plain\", \"images_training\", (368, 368), model.center_map)\n",
    "dataset_valid = ImageDataset(\"heat_maps_valid_plain\", \"images_valid\", (368, 368), model.center_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T19:36:49.292824Z",
     "iopub.status.busy": "2024-07-22T19:36:49.292312Z",
     "iopub.status.idle": "2024-07-22T19:36:49.301334Z",
     "shell.execute_reply": "2024-07-22T19:36:49.300501Z",
     "shell.execute_reply.started": "2024-07-22T19:36:49.292799Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T19:36:49.303021Z",
     "iopub.status.busy": "2024-07-22T19:36:49.302226Z",
     "iopub.status.idle": "2024-07-22T19:36:49.305836Z",
     "shell.execute_reply": "2024-07-22T19:36:49.305281Z",
     "shell.execute_reply.started": "2024-07-22T19:36:49.302996Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epoch = 3\n",
    "batch_size = 8\n",
    "store_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T19:36:49.307148Z",
     "iopub.status.busy": "2024-07-22T19:36:49.306581Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "8001it [36:03,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 0.1799 | Train Accuracy: 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:02,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc = 0.1823529411764706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7348it [33:26,  3.20it/s]"
     ]
    }
   ],
   "source": [
    "store_dict = train(model=model, num_epochs=num_epoch, train_loader=dataset_training, test_loader=dataset_valid, store_dict=store_dict, device = device, loss_function = loss_function, optimizer=optimizer, batch_size = batch_size)\n",
    "store_dict_to_disk('store_dict.json', store_dict=store_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'/notebooks/lk-s-2024-detekcija-poze/model22.7.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load('model22.7.pth')\n",
    "loaded_model.eval()\n",
    "\n",
    "input1 = dataset_test[0][0]\n",
    "input1 = input1.to(device)\n",
    "output = loaded_model(input1)\n",
    "output = output.cpu()\n",
    "numpy_array = output.detach().numpy()\n",
    "plt.imshow(numpy_array[0]*255)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
