{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T20:19:36.041701Z",
     "iopub.status.busy": "2024-07-23T20:19:36.041383Z",
     "iopub.status.idle": "2024-07-23T20:19:36.047489Z",
     "shell.execute_reply": "2024-07-23T20:19:36.046791Z",
     "shell.execute_reply.started": "2024-07-23T20:19:36.041674Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from utilss import get_accuracy, plot_curve, keep_store_dict, store_dict_to_disk\n",
    "from data_loader import DataLoader1, ImageDataset\n",
    "from initializers import gaussian_initializer, constant_initializer\n",
    "from models import Model3, ModelM2, ModelM3, Model2, Model1, ModelAVE, Model\n",
    "from test import test\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T20:19:36.049199Z",
     "iopub.status.busy": "2024-07-23T20:19:36.048972Z",
     "iopub.status.idle": "2024-07-23T20:19:37.296181Z",
     "shell.execute_reply": "2024-07-23T20:19:37.295340Z",
     "shell.execute_reply.started": "2024-07-23T20:19:36.049175Z"
    }
   },
   "outputs": [],
   "source": [
    "model1 = Model1()\n",
    "model2 = Model2()\n",
    "modelAVE = ModelAVE()\n",
    "model2_M = ModelM2()\n",
    "model3 = Model3()\n",
    "model3_M = ModelM3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T20:19:37.300430Z",
     "iopub.status.busy": "2024-07-23T20:19:37.300171Z",
     "iopub.status.idle": "2024-07-23T20:19:37.592793Z",
     "shell.execute_reply": "2024-07-23T20:19:37.592001Z",
     "shell.execute_reply.started": "2024-07-23T20:19:37.300405Z"
    }
   },
   "outputs": [],
   "source": [
    "#model = Model(model1, model2, model3, modelAVE, model2_M, model3_M)\n",
    "model = Model1()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T20:19:37.594227Z",
     "iopub.status.busy": "2024-07-23T20:19:37.594001Z",
     "iopub.status.idle": "2024-07-23T20:19:37.597905Z",
     "shell.execute_reply": "2024-07-23T20:19:37.597111Z",
     "shell.execute_reply.started": "2024-07-23T20:19:37.594203Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epoch = 3\n",
    "batch_size = 8\n",
    "store_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T20:19:37.600239Z",
     "iopub.status.busy": "2024-07-23T20:19:37.600006Z",
     "iopub.status.idle": "2024-07-23T20:19:37.605246Z",
     "shell.execute_reply": "2024-07-23T20:19:37.604345Z",
     "shell.execute_reply.started": "2024-07-23T20:19:37.600215Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_test = ImageDataset(\"heat_maps_test_plain\", \"images_test\", (368, 368), model.center_map)\n",
    "dataset_training = ImageDataset(\"heat_maps_training_plain\", \"images_training\", (368, 368), model.center_map)\n",
    "dataset_valid = ImageDataset(\"heat_maps_valid_plain\", \"images_valid\", (368, 368), model.center_map)\n",
    "\n",
    "\n",
    "#test_data_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T20:19:37.607220Z",
     "iopub.status.busy": "2024-07-23T20:19:37.606898Z",
     "iopub.status.idle": "2024-07-23T20:19:37.612421Z",
     "shell.execute_reply": "2024-07-23T20:19:37.611355Z",
     "shell.execute_reply.started": "2024-07-23T20:19:37.607196Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T20:19:37.614096Z",
     "iopub.status.busy": "2024-07-23T20:19:37.613869Z",
     "iopub.status.idle": "2024-07-23T20:19:40.955346Z",
     "shell.execute_reply": "2024-07-23T20:19:40.953474Z",
     "shell.execute_reply.started": "2024-07-23T20:19:37.614072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "0it [00:03, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m store_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_training\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstore_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m store_dict_to_disk(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_dict.json\u001b[39m\u001b[38;5;124m'\u001b[39m, store_dict\u001b[38;5;241m=\u001b[39mstore_dict)\n",
      "File \u001b[0;32m/notebooks/lk-s-2024-detekcija-poze/train.py:37\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, num_epochs, train_loader, store_dict, test_loader, device, loss_function, optimizer, batch_size)\u001b[0m\n\u001b[1;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(y_hat\u001b[38;5;241m.\u001b[39mfloat(), y\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     36\u001b[0m train_running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 37\u001b[0m train_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mget_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m     40\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/notebooks/lk-s-2024-detekcija-poze/utilss.py:33\u001b[0m, in \u001b[0;36mget_accuracy\u001b[0;34m(l1, l2)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(size[\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(size[\u001b[38;5;241m2\u001b[39m]):\n\u001b[0;32m---> 33\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m list1[i][j][k] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     34\u001b[0m             koordsx1[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m k \n\u001b[1;32m     35\u001b[0m             koordsy1[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m j \n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "store_dict = train(model=model, num_epochs=num_epoch, train_loader=dataset_training, test_loader=dataset_valid, store_dict=store_dict, device = device, loss_function = loss_function, optimizer=optimizer, batch_size = batch_size)\n",
    "store_dict_to_disk('store_dict.json', store_dict=store_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-23T20:19:40.956817Z",
     "iopub.status.idle": "2024-07-23T20:19:40.957285Z",
     "shell.execute_reply": "2024-07-23T20:19:40.957076Z",
     "shell.execute_reply.started": "2024-07-23T20:19:40.957050Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model,'/notebooks/lk-s-2024-detekcija-poze/model23_71.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-23T20:19:40.959014Z",
     "iopub.status.idle": "2024-07-23T20:19:40.959382Z",
     "shell.execute_reply": "2024-07-23T20:19:40.959221Z",
     "shell.execute_reply.started": "2024-07-23T20:19:40.959205Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_model = torch.load('model23_7_2.pth')\n",
    "loaded_model.eval()\n",
    "\n",
    "input1 = dataset_training[5][0]\n",
    "input1a = input1.cpu()\n",
    "image_to_display = np.transpose(input1a, (1, 2, 0))\n",
    "plt.imshow(image_to_display)\n",
    "plt.show()\n",
    "input1 = input1.to(device)\n",
    "a = ['r ankle','r knee','r hip', 'l hipl', 'knee_X','l ankle_X','pelvis','thorax','upper neck','head top','r wrist','r elbow', 'r shoulder', 'l shoulder','l elbow','l wrist', 'back']\n",
    "for i in range(17):\n",
    "    output = loaded_model(input1)\n",
    "    output = output.cpu()\n",
    "    numpy_array = output.detach().numpy()\n",
    "    plt.imshow(numpy_array[i]*255)\n",
    "    plt.xlabel(a[i])\n",
    "    plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-23T20:19:40.961188Z",
     "iopub.status.idle": "2024-07-23T20:19:40.961577Z",
     "shell.execute_reply": "2024-07-23T20:19:40.961403Z",
     "shell.execute_reply.started": "2024-07-23T20:19:40.961377Z"
    }
   },
   "outputs": [],
   "source": [
    "input1 = dataset_training[7060][0]\n",
    "input1a = input1.cpu()\n",
    "image_to_display = np.transpose(input1a, (1, 2, 0))\n",
    "plt.imshow(image_to_display)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
